{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sveučilište u Zagrebu<br>\n",
    "Fakultet elektrotehnike i računarstva\n",
    "\n",
    "## Strojno učenje 2016./2017.\n",
    "\n",
    "<a href=\"http://www.fer.unizg.hr/predmet/su\">http://www.fer.unizg.hr/predmet/su</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laboratorijska vježba 1: Regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objavljeno: **12. listopada 2016.**<br>\n",
    "Rok za predaju: U terminu vježbe u tjednu od **17. listopada 2016.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upute\n",
    "\n",
    "Prva laboratorijska vježba sastoji se od **sedam** zadataka. Kako bi kvalitetnije, ali i na manje zamoran način usvojili gradivo ovog kolegija, potrudili smo se uključiti tri vrste zadataka: **1)** implementacija manjih algoritama, modela ili postupaka; **2)** eksperimenti s raznim modelima te njihovim hiperparametrima, te **3)** primjena modela na (stvarnim) podatcima. Ovim zadatcima pokrivamo dvije paradigme učenja: učenje izgradnjom (engl. *learning by building*) i učenje eksperimentiranjem (engl. *learning by experimenting*).\n",
    "\n",
    "U nastavku slijedite upute navedene u ćelijama s tekstom. Rješavanje vježbe svodi se na **dopunjavanje ove bilježnice**: umetanja ćelije ili više njih **ispod** teksta zadatka, pisanja odgovarajućeg kôda te evaluiranja ćelija. \n",
    "\n",
    "Osigurajte da u potpunosti **razumijete** kôd koji ste napisali. Kod predaje vježbe, morate biti u stanju na zahtjev asistenta (ili demonstratora) preinačiti i ponovno evaluirati Vaš kôd. Nadalje, morate razumjeti teorijske osnove onoga što radite, u okvirima onoga što smo obradili na predavanju. Ispod nekih zadataka možete naći i pitanja koja služe kao smjernice za bolje razumijevanje gradiva (**nemojte pisati** odgovore na pitanja u bilježnicu). Stoga se nemojte ograničiti samo na to da riješite zadatak, nego slobodno eksperimentirajte. To upravo i jest svrha ovih vježbi.\n",
    "\n",
    "Vježbe trebate raditi **samostalno**. Možete se konzultirati s drugima o načelnom načinu rješavanja, ali u konačnici morate sami odraditi vježbu. U protivnome vježba nema smisla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Učitaj osnovne biblioteke...\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadatci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Univarijatna regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadan je skup primjera $\\mathcal{D}=\\{(x^{(i)},y^{(i)})\\}_{i=1}^4 = \\{(0,4),(1,1),(2,2),(4,5)\\}$. Primjere predstavite matrixom $\\mathbf{X}$ dimenzija $N\\times n$ (u ovom slučaju $4\\times 1$) i vektorom oznaka $\\textbf{y}$, dimenzija $N\\times 1$ (u ovom slučaju $4\\times 1$), na sljedeći način:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([[0],[1],[2],[4]])\n",
    "y = np.array([4,1,2,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Proučite funkciju [`PolynomialFeatures`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) iz biblioteke `sklearn` i upotrijebite je za generiranje dizajn-matrice $\\mathbf{\\Phi}$ koja ne koristi preslikavanje u prostor više dimenzije (samo će svakom primjeru biti dodane *dummy* jedinice; $m=n+1$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [4]]\n",
      "[[ 1.  0.]\n",
      " [ 1.  1.]\n",
      " [ 1.  2.]\n",
      " [ 1.  4.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "designMatrix = X\n",
    "degree = 1 # if degree > 1, construct n-degree polynomial\n",
    "features = PolynomialFeatures(degree)\n",
    "print X\n",
    "X = features.fit_transform(X)\n",
    "print X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upoznajte se s modulom [`linalg`](http://docs.scipy.org/doc/numpy/reference/routines.linalg.html). Izračunajte težine $\\mathbf{w}$ modela linearne regresije kao $\\mathbf{w}=(\\mathbf{\\Phi}^\\intercal\\mathbf{\\Phi})^{-1}\\mathbf{\\Phi}^\\intercal\\mathbf{y}$. Zatim se uvjerite da isti rezultat možete dobiti izračunom pseudoinverza $\\mathbf{\\Phi}^+$ dizajn-matrice, tj. $\\mathbf{w}=\\mathbf{\\Phi}^+\\mathbf{y}$, korištenjem funkcije [`pinv`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.pinv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.2         0.45714286]\n",
      "[ 2.2         0.45714286]\n",
      "[ 2.2         0.45714286]\n"
     ]
    }
   ],
   "source": [
    "XT = X.transpose()\n",
    "XTmulX = np.dot(XT, X)\n",
    "XTmulXinv = np.linalg.inv(XTmulX)\n",
    "w = np.dot(np.dot(XTmulXinv, XT), y)\n",
    "print w\n",
    "\n",
    "w = np.dot(np.linalg.pinv(X), y)\n",
    "print w\n",
    "\n",
    "w = w.transpose()\n",
    "print w #the transpose has happened but it doesn't effect the repr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radi jasnoće, u nastavku je vektor $\\mathbf{x}$ s dodanom *dummy* jedinicom $x_0=1$ označen kao $\\tilde{\\mathbf{x}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prikažite primjere iz $\\mathcal{D}$ i funkciju $h(\\tilde{\\mathbf{x}})=\\mathbf{w}^\\intercal\\tilde{\\mathbf{x}}$. Izračunajte pogrešku učenja prema izrazu $E(h|\\mathcal{D})=\\frac{1}{2}\\sum_{i=1}^N(\\tilde{\\mathbf{x}}^{(i)} - h(\\tilde{\\mathbf{x}}))^2$. Možete koristiti funkciju srednje kvadratne pogreške [`mean_squared_error`]( http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) iz modula [`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics).\n",
    "\n",
    "**Q:** Gore definirana funkcija pogreške $E(h|\\mathcal{D})$ i funkcija srednje kvadratne pogreške nisu posve identične. U čemu je razlika? Koja je \"realnija\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 2 5]\n",
      "[ 2.2         2.65714286  3.11428571  4.02857143]\n",
      "2.04285714286\n",
      "4.08571428571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "predictions = np.dot(X, w)\n",
    "print y\n",
    "print predictions\n",
    "\n",
    "print mean_squared_error(y, predictions)\n",
    "print mean_squared_error(y, predictions) * len(X)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uvjerite se da za primjere iz $\\mathcal{D}$ težine $\\mathbf{w}$ ne možemo naći rješavanjem sustava $\\mathbf{w}=\\mathbf{\\Phi}^{-1}\\mathbf{y}$, već da nam doista treba pseudoinverz.\n",
    "\n",
    "**Q:** Zašto je to slučaj? Bi li se problem mogao riješiti preslikavanjem primjera u višu dimenziju? Ako da, bi li to uvijek funkcioniralo, neovisno o skupu primjera $\\mathcal{D}$? Pokažite na primjeru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3]\n",
      " [1 5 1 1]\n",
      " [2 1 1 1]\n",
      " [4 1 1 1]]\n",
      "[[ 0.     0.    -0.5    0.5  ]\n",
      " [ 0.     0.25  -0.375  0.125]\n",
      " [-1.    -0.5    6.75  -3.25 ]\n",
      " [ 1.     0.25  -4.375  2.125]]\n",
      "[ 1.5    0.125 -7.25   6.125]\n"
     ]
    }
   ],
   "source": [
    "#print np.linalg.inv(X) #cannot do that. The matrix isn't a square matrix.\n",
    "XHighD = np.array([[0,1,2,3],\n",
    "                   [1,5,1,1],\n",
    "                   [2,1,1,1],\n",
    "                   [4,1,1,1],  \n",
    "                  ])\n",
    "print XHighD\n",
    "XHighDinv = np.linalg.inv(XHighD)\n",
    "print XHighDinv\n",
    "print np.dot(XHighDinv,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proučite klasu [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) iz modula [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model). Uvjerite se da su težine koje izračunava ta funkcija (dostupne pomoću atributa `coef_` i `intercept_`) jednake onima koje ste izračunali gore. Izračunajte predikcije modela (metoda `predict`) i uvjerite se da je pogreška učenja identična onoj koju ste ranije izračunali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.45714286]\n",
      "2.2\n",
      "[ 2.2         2.65714286  3.11428571  4.02857143]\n",
      "[ 2.2         2.65714286  3.11428571  4.02857143]\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "wi = model.coef_\n",
    "print wi\n",
    "w0 = model.intercept_\n",
    "print w0\n",
    "\n",
    "print predictions\n",
    "print model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Polinomijalna regresija i utjecaj šuma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Razmotrimo sada regresiju na većem broju primjera. Definirajte funkciju `make_labels(X, f, noise=0)` koja uzima matricu neoznačenih primjera $\\mathbf{X}_{N\\times n}$ te generira vektor njihovih oznaka $\\mathbf{y}_{N\\times 1}$. Oznake se generiraju kao $y^{(i)} = f(x^{(i)})+\\mathcal{N}(0,\\sigma^2)$, gdje je $f:\\mathbb{R}^n\\to\\mathbb{R}$ stvarna funkcija koja je generirala podatke (koja nam je u stvarnosti nepoznata), a $\\sigma$ je standardna devijacija Gaussovog šuma, definirana parametrom `noise`. Za generiranje šuma možete koristiti funkciju [`numpy.random.normal`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.normal.html). \n",
    "\n",
    "Generirajte skup za učenje od $N=50$ primjera uniformno distribuiranih u intervalu $[-5,5]$ pomoću funkcije $f(x) = 5 + x -2 x^2 -5 x^3$ uz šum  $\\sigma=200$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.random import normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.68340266 -4.29802813 -4.38796304 -3.06159689 -3.28420555  2.77569142\n",
      "  4.5172652   4.15956171  3.12811726  3.34848891  2.56379485  2.31895742\n",
      "  2.34846852  3.13913982  1.12250743 -3.33363124  4.31417869  0.43156325\n",
      "  4.09012814  1.82386094  0.22241019  0.05422376  3.01496876  2.80651155\n",
      "  2.14170546  2.34266713 -2.65248386 -4.22605844  2.53736276  3.07654254\n",
      "  0.436798   -4.61678567  2.2722617  -4.84694305  2.91472725 -0.32446969\n",
      " -1.7179248  -2.57924041  3.71764997 -0.84469114 -4.05697836  1.90798951\n",
      "  3.04692512 -3.08212115  1.68805658  4.60201452 -4.39227438 -2.11014326\n",
      "  3.83765667 -1.98138936]\n",
      "[-396.9211893   322.1260251   517.97621806  114.87520984  410.52122327\n",
      "  353.36623673 -404.82609326 -557.9027502  -374.14757441 -654.68670335\n",
      " -260.26594366  119.06314173 -568.51720052 -279.7090088   215.79276381\n",
      "  -22.79173047 -235.9352399   255.30403673 -722.12604026 -294.13441171\n",
      "  236.79999745 -101.54816724 -329.96068429 -123.29649696  153.24269846\n",
      " -146.22834749 -312.69570313  460.98514497  -69.15775482  102.78846873\n",
      " -122.83590148  330.5356577  -198.06297052  587.77866516 -163.25570635\n",
      "   45.31663009  171.19783641  244.37660557  -86.63191327  -15.57561179\n",
      "  426.60285183  -69.00804351   16.58338644  281.48137457 -260.61082745\n",
      " -716.75376034   -2.15722108 -110.48791025 -388.33242647 -191.47280945]\n"
     ]
    }
   ],
   "source": [
    "from random import uniform\n",
    "# N \"tall\"\n",
    "# n \"wide\"\n",
    "# noise is standard deviation, sigma\n",
    "\n",
    "def make_labels(X, f, noise=0) :\n",
    "    return np.array([(f(x) + np.random.normal(0, noise)) for x in X]).transpose()\n",
    "\n",
    "def function(x):\n",
    "    return 5+x-2*x*x-5*x*x*x\n",
    "\n",
    "N = 50\n",
    "X = np.array([uniform(-5,5) for number in xrange(N)]).transpose()\n",
    "print X\n",
    "f = function\n",
    "y = make_labels(X, f, 200)\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prikažite taj skup funkcijom [`scatter`](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0xdf54e80>"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFJCAYAAABU5W56AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xde948d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenirajte model polinomijalne regresije stupnja $d=3$. Na istom grafikonu prikažite naučeni model $h(\\mathbf{x})=\\mathbf{w}^\\intercal\\tilde{\\mathbf{x}}$ i primjere za učenje. Izračunajte pogrešku učenja modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Odabir modela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Na skupu podataka iz zadatka 2 trenirajte pet modela linearne regresije $\\mathcal{H}_d$ različite složenosti, gdje je $d$ stupanj polinoma, $d\\in\\{1,3,5,10,20\\}$. Prikažite na istome grafikonu skup za učenje i funkcije $h_d(\\mathbf{x})$ za svih pet modela (preporučujemo koristiti `plot` unutar `for` petlje). Izračunajte pogrešku učenja svakog od modela.\n",
    "\n",
    "**Q:** Koji model ima najmanju pogrešku učenja i zašto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Razdvojite skup primjera iz zadatka 2 pomoću funkcije [`cross_validation.train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html#sklearn.cross_validation.train_test_split) na skup za učenja i skup za ispitivanje u omjeru 1:1. Prikažite na jednom grafikonu pogrešku učenja i ispitnu pogrešku za modele polinomijalne regresije $\\mathcal{H}_d$, sa stupnjem polinoma $d$ u rasponu $d\\in\\{1,20\\}$. Radi preciznosti, funkcije $h(\\mathbf{x})$ iscrtajte na cijelom skupu primjera (ali pogrešku generalizacije računajte, naravno, samo na ispitnome skupu). Budući da kvadratna pogreška brzo raste za veće stupnjeve polinoma, umjesto da iscrtate izravno iznose pogrešaka, iscrtajte njihove logaritme.\n",
    "\n",
    "**NB:** Podjela na skupa za učenje i skup za ispitivanje mora za svih pet modela biti identična.\n",
    "\n",
    "**Q:** Je li rezultat u skladu s očekivanjima? Koji biste model odabrali i zašto?\n",
    "\n",
    "**Q:** Pokrenite iscrtavanje više puta. U čemu je problem? Bi li problem bio jednako izražen kad bismo imali više primjera? Zašto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Točnost modela ovisi o (1) njegovoj složenosti (stupanj $d$ polinoma), (2) broju primjera $N$, i (3) količini šuma. Kako biste to analizirali, nacrtajte grafikone pogrešaka kao u 3b, ali za sve kombinacija broja primjera $N\\in\\{100,200,1000\\}$ i količine šuma $\\sigma\\in\\{100,200,500\\}$ (ukupno 9 grafikona). Upotrijebite funkciju [`subplots`](http://matplotlib.org/examples/pylab_examples/subplots_demo.html) kako biste pregledno posložili grafikone u tablicu $3\\times 3$. Podatci se generiraju na isti način kao u zadatku 2.\n",
    "\n",
    "**NB:** Pobrinite se da svi grafikoni budu generirani nad usporedivim skupovima podataka, na sljedeći način. Generirajte najprije svih 1000 primjera, podijelite ih na skupove za učenje i skupove za ispitivanje (dva skupa od po 500 primjera). Zatim i od skupa za učenje i od skupa za ispitivanje načinite tri različite verzije, svaka s drugačijom količinom šuma (ukupno 2x3=6 verzija podataka). Kako bi simulirali veličinu skupa podataka, od tih dobivenih 6 skupova podataka uzorkujte trećinu, dvije trećine i sve podatke. Time ste dobili 18 skupova podataka -- skup za učenje i za testiranje za svaki od devet grafova."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q:*** Jesu li rezultati očekivani? Obrazložite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Regularizirana regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "U gornjim eksperimentima nismo koristili **regularizaciju**. Vratimo se najprije na primjer iz zadatka 1. Na primjerima iz tog zadatka izračunajte težine $\\mathbf{w}$ za polinomijalni regresijski model stupnja $d=3$ uz L2-regularizaciju (tzv. *ridge regression*), prema izrazu $\\mathbf{w}=(\\mathbf{\\Phi}^\\intercal\\mathbf{\\Phi}+\\lambda\\mathbf{I})^{-1}\\mathbf{\\Phi}^\\intercal\\mathbf{y}$. Napravite izračun težina za regularizacijske faktore $\\lambda=0$, $\\lambda=1$ i $\\lambda=10$ te usporedite dobivene težine.\n",
    "\n",
    "**Q:** Kojih je dimenzija matrica koju treba invertirati?\n",
    "\n",
    "**Q:** Po čemu se razlikuju dobivene težine i je li ta razlika očekivana? Obrazložite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proučite klasu [`Ridge`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) iz modula [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model), koja implementira L2-regularizirani regresijski model. Parametar $\\alpha$ odgovara parametru $\\lambda$. Primijenite model na istim primjerima kao u prethodnom zadatku i ispišite težine $\\mathbf{w}$ (atributi `coef_` i `intercept_`).\n",
    "\n",
    "**Q:** Jesu li težine identične onima iz zadatka 4a? Ako nisu, objasnite zašto je to tako i kako biste to popravili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Regularizirana polinomijalna regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Vratimo se na slučaj $N=50$ slučajno generiranih primjera iz zadatka 2. Trenirajte modele polinomijalne regresije $\\mathcal{H}_{\\lambda,d}$ za $\\lambda\\in\\{0,100\\}$ i $d\\in\\{2,10\\}$ (ukupno četiri modela). Skicirajte pripadne funkcije $h(\\mathbf{x})$ i primjere (na jednom grafikonu; preporučujemo koristiti `plot` unutar `for` petlje).\n",
    "\n",
    "**Q:** Jesu li rezultati očekivani? Obrazložite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)\n",
    "\n",
    "Kao u zadataku 3b, razdvojite primjere na skup za učenje i skup za ispitivanje u omjeru 1:1. Prikažite krivulje logaritama pogreške učenja i ispitne pogreške u ovisnosti za model $\\mathcal{H}_{d=20,\\lambda}$, podešavajući faktor regularizacije $\\lambda$ u rasponu $\\lambda\\in\\{0,1,\\dots,50\\}$.\n",
    "\n",
    "**Q:** Kojoj strani na grafikonu odgovara područje prenaučenosti a kojoj podnaučenosti. Zašto?\n",
    "\n",
    "**Q:** Koju biste vrijednosti za $\\lambda$ izabrali na temelju ovih grafikona i zašto?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. L1-regularizacija i L2-regularizacija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svrha regularizacije jest potiskivanje težina modela $\\mathbf{w}$ prema nuli, kako bi model bio što jednostavniji. Složenost modela može se okarakterizirati normom pripadnog vektora težina $\\mathbf{w}$, i to tipično L2-normom ili L1-normom. Za jednom trenirani model možemo izračunati i broj ne-nul značajki, ili L0-normu, pomoću sljedeće funkcije:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nonzeroes(coef, tol=1e-6): \n",
    "    return len(coef) - len(coef[sp.isclose(0, coef, atol=tol)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Za ovaj zadatak upotrijebite skup za učenje i skup za testiranje iz zadatka 3b. Trenirajte modele **L2-regularizirane** polinomijalne regresije stupnja $d=20$, mijenjajući hiperparametar $\\lambda$ u rasponu $\\{1,2,\\dots,100\\}$. Za svaki od treniranih modela izračunajte L{0,1,2}-norme vektora težina $\\mathbf{w}$ te ih prikažite kao funkciju od $\\lambda$.\n",
    "\n",
    "**Q:** Objasnite oblik obiju krivulja. Hoće li krivulja za $\\|\\mathbf{w}\\|_2$ doseći nulu? Zašto? Je li to problem? Zašto?\n",
    "\n",
    "**Q:** Za $\\lambda=100$, koliki je postotak težina modela jednak nuli, odnosno koliko je model rijedak?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glavna prednost L1-regularizirane regresije (ili *LASSO regression*) nad L2-regulariziranom regresijom jest u tome što L1-regularizirana regresija rezultira **rijetkim modelima** (engl. *sparse models*), odnosno modelima kod kojih su mnoge težine pritegnute na nulu. Pokažite da je to doista tako, ponovivši gornji eksperiment s **L1-regulariziranom** regresijom, implementiranom u klasi  [`Lasso`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) u modulu [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Predviđanje cijena nekretnina u Bostonu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do sada smo razmatrali isključivo univarijatnu regresiju, tj. imali smo samo jednu značajku ($n=1$). U većini stvarnih problema baratamo s većim brojem značajki. Razmotrimo sada jedan nešto realniji problem, kod kojega postoji više značajki, pa je potrebno napraviti multivarijatnu regresiju.\n",
    "\n",
    "Učitajte skup podataka *Boston House Prices*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506L, 13L)\n",
      "(506L,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print boston.data.shape\n",
    "print boston.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skup sadrži 506 primjera sa 13 numeričkih značajki. Opis skupa možete dobiti na sljedeći način:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print boston.DESCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaš je zadatak da izgradite regresijski model za predviđanje cijene nekretnine (`y=boston.target`) na temelju 13 raspoloživih značajki za svaku nekretninu (`X=boston.data`). Cilj je pronaći najbolji mogući linearni model regresije na ovom skupu podataka i provjeriti njegovu točnost u smislu pogreške kvadratnog odstupanja ([`mean_squared_error`]( http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error)). \n",
    "\n",
    "Hiperparametri modela koje treba isprobati su:\n",
    "\n",
    "* **Regularizacija:** Bez regularizacije ([`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)), L2-regularizacija ([`Ridge`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge)) i L1-regularizacija ([`Lasso`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso));\n",
    "* **Značajke:** Izvornih 13 značajki, polinomijalne značajke (isprobajte različite stupnjeve polinoma $d$), samo interakcijske značajke (opcija `interaction_only` u klasi [`PolynomialFeatures`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html));\n",
    "\n",
    "Kao i inače, za odabir i ispitivanje modela koristit ćemo **unakrsnu provjeru** (engl. *cross-validation*). Skup primjera za učenje podijelit ćemo na **skup za učenje**, **skup za provjeru** i **skup za ispitivanje** u omjeru (otprilike) 3:1:1. Kao u uvijek, model trebate trenirati na skupu za učenje, odabir modela (odnosno optimizaciju hiperparametra) trebate provesti na skupu za provjeru, a konačno vrednovanje modela trebate načiniti na skupu za ispitivanje. Konačno vrednovanje radite samo jednom, za model koji ste na skupu za provjeru odabrali kao optimalan.\n",
    "\n",
    "**NB:** Nakon što odaberete optimalan model na skupu za provjeru, prije konačnog ispitivanja odabrani model ponovno trenirajte na uniji skupova za učenje i provjeru. Na taj način iskorištavate maksimalno iskorištavate dostupne podatke i model će u pravilu biti bolji.\n",
    "\n",
    "Podjela na skup za učenje, provjeru i ispitivanje u ovom je slučaju fiksna kako bi svi imali identične skupove i kako bi rezultati bili usporedivi. (U stvarnosti biste ovakav eksperiment radili malo drugačije: koristili biste višestruku unakrsnu provjeru ili ugnježđenu unakrsnu provjeru. Više o tome u budućim vježbama.) \n",
    "\n",
    "Koristite sljedeće skupove:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303L, 13L) (101L, 13L) (102L, 13L)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "X_train, X_rest, y_train, y_rest = cross_validation.train_test_split(boston.data,boston.target,train_size=0.6,random_state=42)\n",
    "X_validate, X_test, y_validate, y_test = cross_validation.train_test_split(X_rest,y_rest,test_size=0.5,random_state=42)\n",
    "print X_train.shape, X_validate.shape ,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaše rješenje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Koliko značajki ima svaki od modela koji ste isprobali?\n",
    "\n",
    "**Q:** Provjerite točnost odabranog modela na (1) skupu za učenje, (2) skupu za provjeru, (3) uniji ta dva skupa i (4) skupu za ispitivanje. Jesu li odnosi između točnosti modela na ova četiri skupa očekivana? Obrazložite.\n",
    "\n",
    "**Q:** Kod treniranja regresijskog modela moguće je postaviti `fit_intercept=False`, čime se izbjegava optimiranje težine $w_0$. Trenirajte odabrani model s tom postavkom. Usporedite s točnošću optimalnog modela. Je li rezultat očekivan? Obrazložite. Ima li predobrada značajki ikakvog utjecaja na ovu razliku?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
