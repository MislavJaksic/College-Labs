Uvod u optimizaciju

Optimum je najbolje moguce stanje.
Optimiranje je kada nesto pokusavamo optimizirati.
Optimizirati je zavrsena radanja.

Ciljna funkcija (eng. objective function) je ona cija max ili min dovodi do trazenog rjesenja.
Funkcija kostanja, vrijednosna funkcija, dobrota je sve sinonim za ciljnu funkciju.

Vrijednost ciljne funkcije mora se moci kontrolirati parametrima. Nadi parametre za koje se postizu najbolji rezultat funkcije cilja.

Predmet optimizacije pretvori u modeel s kontrolnim varijablama (parametrima) s ciljnom funkcijom, te nadi njen ekstrem.
U okviru NASP-a necemo imati uvjete optimiranja, ali inace su vrlo vazni.

Pogreska je razlika izmedu vrijednosti lijeve i desne strane jednadzbe.

Primjer: ako kazemo da je x jednak 1, onda u prvoj jednadzbi necemo imati gresku, ali cemo ih imati u drugoj i treci.
x = 1
x = 2
x = 3
- kriterij najmanjih kvadrata kaze:
  (x-1)**2 + (x-2)**2 + (x-3)**2 treba biti minimalna (pretvori u polinom, pa deriviraj i izjednaci s nulom) 


Gradijent ima znacenje nagiba krivulje.
  - u vise dimenzija pitanje je po kojoj osi deriviramo
Gradijent pokazuje smjer najbrzeg smjera porasta funkcije.

Vektor svih prvih parcijalnih derivacija zove se nablaF (nabla se pise kao obrnuti trokut).
  - temelj gradijentne metoda
  - pokazuje smjer u kojem se hiperploha raste
  - velicina pokazuje koliko brzo raste

Razinski skup (eng. level set) je projekcija skupa svih tocaka u kojem funkcija daje istu vrijednost. Postoji lijepa slika "zdjele" sa svojim izokonturama.
  


Gradijentna metoda pomice vrijednost tocke prema maksimuma. 
  - F(X), F:R->R
  - X = X - alpha*nablaF(X); alpha > 0

Primjer: (x-1)**2 + (x-2)**2 + (x-3)**2
  - gradijent: df/dx = 6*x - 12
  - nablaF = gradijent, X0 = 0, alpha=1/10
  - X1 = X0 - alpha*nablaF(X0)
    - X1 = 0 - (1/10)*(6*X0 - 12)
    - X1 = (-1)*(1/10)*(6*0 - 12)
    - X1 = 12/10
  - X2 = X1 - (1/10)*(6*(12/10) - 12) = 84/50
  - ...


Poglavlje 2: neuronske mreze

Inspirirane pravim bioloskim neuronima. Umjetne neuronske mreze ih oponasaju.
Kruzici su neuroni, a veze izmedu njih crte.

Neuroni su skoro pa elektronicka zbrajala.
Nauciti mrezu znaci podesiti parametre veza izmedu neurona.

Sustav povratne veze je nacin ucenja mreze.
Mreza ima n ulaznih varijabli x. Mreza zatim generira izlaze ovisno o ulazima. Izlazi se usporeduju s pravim vrijednostima. Usporedba daje odredeno odstupanje i ono je pogreska. Pogreska je ulaz u algoritam ucenja koji generira parametre koji poboljsavaju ponasanje mreze. Zatim se postupak generiranja izlaza iz mreze ponavljaju. 

Ovakav sustav naziva se nadzirano ucenje. Postoji i nenadzirano ucenje.

Mreza se sastoji od slojeva. Prvi sloj je ulazni sloj, svi slojevi do zadnjeg su unutarnji slojevi, a zadnji sloj je izlazni sloj.

PAZI! Svi vektori su po dogovoru stupcani.
Kada se kruzic uveca:
  - sastoji se od zbrajala veza (signala) i aktivacijske funckije (sigmoida)
    - mi cemo raditi sa sigmoidama, ali znaj da postoje razlicite funckije
  - da bi mreza funkcionirala, neuroni moraju biti nelinearni
  - izlaz neurona: y = F(SUM(x*w)) <- Adaline (eng. adaptive linear element, Rosenbrock's perceptron)  
                   y = wT*X

Skup za uvjezbavanje, skup primjera je D.
Koristi postupak njamanjih kvadrata (kao i na Strojnom Ucenju) da dobijes pogresku ucenja.

Rjesavat cemo sustave jednadzbi gdje broj nepoznanica i jednadzbi nije jednak.
 